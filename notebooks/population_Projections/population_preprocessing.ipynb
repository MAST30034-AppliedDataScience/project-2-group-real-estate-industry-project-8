{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Total_dwelings', 'G34', 'G30'), ('Tot_P_P', 'G01', 'G01')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# years we are dealing with\n",
    "years = [(2021, \"SA2_CODE_2021\", \"SA2\", \"Statistical Area 2\"), (2016, \"SA2_MAINCODE_2016\", \"SA2\", \"Statistical Area 2\")]\n",
    "\n",
    "# fields we want to extract and the file the data is in : \n",
    "# Creating the list of tuples with the shorthand name and G01 or G02 group.\n",
    "fields_with_names = [\n",
    "    (\"Total_dwelings\", \"G34\",\"G30\"),\n",
    "    (\"Tot_P_P\",\"G01\", \"G01\")\n",
    "]\n",
    "\n",
    "\n",
    "fields_with_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "path = '../../data/landing/'\n",
    "\n",
    "for i, (year, code, tp, full_nm) in enumerate(years):\n",
    "    # Create an empty DataFrame for each year to append data into\n",
    "    yearly_df = pd.DataFrame()\n",
    "    \n",
    "    full_path = path + f\"{year}_GCP_{tp}_for_VIC_short-header/{year} Census GCP {full_nm} for VIC/\"\n",
    "\n",
    "    for data in fields_with_names:\n",
    "        # Construct the file path based on year and group\n",
    "        file = f\"{full_path}{year}Census_{data[1 + i]}_VIC_{tp}.csv\"\n",
    "        \n",
    "        # Read the CSV into a pandas DataFrame\n",
    "        pandas_df = pd.read_csv(file)\n",
    "        \n",
    "        # Filter to only keep the fields of interest (code and the specific field)\n",
    "        pandas_df = pandas_df[[code, data[0]]]\n",
    "        \n",
    "        # If the yearly_df is empty, initialize it with the code column\n",
    "        if yearly_df.empty:\n",
    "            yearly_df[code] = pandas_df[code]\n",
    "        \n",
    "        # Add the specific field to the yearly DataFrame\n",
    "        yearly_df[data[0]] = pandas_df[data[0]]\n",
    "\n",
    "    # Append the complete DataFrame for the year to the datasets list\n",
    "    datasets.append(yearly_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_CODE_2021</th>\n",
       "      <th>Total_dwelings</th>\n",
       "      <th>Tot_P_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201011001</td>\n",
       "      <td>5763</td>\n",
       "      <td>16835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201011002</td>\n",
       "      <td>5036</td>\n",
       "      <td>12131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201011005</td>\n",
       "      <td>2522</td>\n",
       "      <td>7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201011006</td>\n",
       "      <td>3870</td>\n",
       "      <td>10661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201011007</td>\n",
       "      <td>1395</td>\n",
       "      <td>4230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SA2_CODE_2021  Total_dwelings  Tot_P_P\n",
       "0      201011001            5763    16835\n",
       "1      201011002            5036    12131\n",
       "2      201011005            2522     7261\n",
       "3      201011006            3870    10661\n",
       "4      201011007            1395     4230"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_MAINCODE_2016</th>\n",
       "      <th>Total_dwelings</th>\n",
       "      <th>Tot_P_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201011001</td>\n",
       "      <td>3886</td>\n",
       "      <td>11654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201011002</td>\n",
       "      <td>4654</td>\n",
       "      <td>12046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201011003</td>\n",
       "      <td>8992</td>\n",
       "      <td>23083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201011004</td>\n",
       "      <td>9868</td>\n",
       "      <td>24231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201011005</td>\n",
       "      <td>2281</td>\n",
       "      <td>7153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SA2_MAINCODE_2016  Total_dwelings  Tot_P_P\n",
       "0          201011001            3886    11654\n",
       "1          201011002            4654    12046\n",
       "2          201011003            8992    23083\n",
       "3          201011004            9868    24231\n",
       "4          201011005            2281     7153"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0] = datasets[0].rename(columns={\"SA2_CODE_2021\": 'SA2_CODE'})\n",
    "datasets[1] = datasets[1].rename(columns={\"SA2_MAINCODE_2016\": 'SA2_CODE'})\n",
    "\n",
    "years = [2021, 2016]\n",
    "\n",
    "data_per_year = {x: datasets[i] for i,x in enumerate(years)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GCCSA</th>\n",
       "      <th>SA4 Code</th>\n",
       "      <th>SA3 Code</th>\n",
       "      <th>SA2  code</th>\n",
       "      <th>Region Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>2021</th>\n",
       "      <th>2026</th>\n",
       "      <th>2031</th>\n",
       "      <th>2036</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2RVIC</td>\n",
       "      <td>201.0</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>201011001.0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Alfredton</td>\n",
       "      <td>6245.0</td>\n",
       "      <td>8252.000000</td>\n",
       "      <td>9732.000000</td>\n",
       "      <td>10830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2RVIC</td>\n",
       "      <td>201.0</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>201011002.0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Ballarat</td>\n",
       "      <td>5970.0</td>\n",
       "      <td>6134.548371</td>\n",
       "      <td>6350.037451</td>\n",
       "      <td>6553.095884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2RVIC</td>\n",
       "      <td>201.0</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>201011005.0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Buninyong</td>\n",
       "      <td>2768.0</td>\n",
       "      <td>2943.325691</td>\n",
       "      <td>3199.637967</td>\n",
       "      <td>3445.433425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2RVIC</td>\n",
       "      <td>201.0</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>201011006.0</td>\n",
       "      <td>SA2</td>\n",
       "      <td>Delacombe</td>\n",
       "      <td>4172.0</td>\n",
       "      <td>6585.376102</td>\n",
       "      <td>8740.266903</td>\n",
       "      <td>10770.851234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GCCSA  SA4 Code  SA3 Code    SA2  code Region Type     Region    2021  \\\n",
       "0    NaN       NaN       NaN          NaN         NaN        NaN     NaN   \n",
       "1  2RVIC     201.0   20101.0  201011001.0         SA2  Alfredton  6245.0   \n",
       "2  2RVIC     201.0   20101.0  201011002.0         SA2   Ballarat  5970.0   \n",
       "3  2RVIC     201.0   20101.0  201011005.0         SA2  Buninyong  2768.0   \n",
       "4  2RVIC     201.0   20101.0  201011006.0         SA2  Delacombe  4172.0   \n",
       "\n",
       "          2026         2031          2036  \n",
       "0          NaN          NaN           NaN  \n",
       "1  8252.000000  9732.000000  10830.000000  \n",
       "2  6134.548371  6350.037451   6553.095884  \n",
       "3  2943.325691  3199.637967   3445.433425  \n",
       "4  6585.376102  8740.266903  10770.851234  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get projections\n",
    "projections = pd.read_excel('../../data/landing/VIF2023_SA2_Pop_Hhold_Dwelling_Projections_to_2036_Release_2.xlsx', sheet_name='Total_Population', skiprows=9)\n",
    "projections.head()\n",
    "\n",
    "dwelling_projections = pd.read_excel('../../data/landing/VIF2023_SA2_Pop_Hhold_Dwelling_Projections_to_2036_Release_2.xlsx', sheet_name='Total_Dwellings', skiprows=9)\n",
    "\n",
    "projections = projections.drop(0)\n",
    "dwelling_projections.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      'GCCSA',    'SA4 Code',    'SA3 Code',   'SA2  code',\n",
       "       'Region Type',      'Region',          2021,          2026,\n",
       "                2031,          2036],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwelling_projections.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2026, 2031, 2036]\n",
    "\n",
    "projections_refined = projections[['SA2  code', *years]]\n",
    "dwellings_refined = dwelling_projections[['SA2  code', *years]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine on SA2 code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA2_CODE</th>\n",
       "      <th>Tot_P_P</th>\n",
       "      <th>Total_dwelings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201011001</td>\n",
       "      <td>20756.256163</td>\n",
       "      <td>8252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201011002</td>\n",
       "      <td>11698.293593</td>\n",
       "      <td>6134.548371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201011005</td>\n",
       "      <td>7372.079773</td>\n",
       "      <td>2943.325691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201011006</td>\n",
       "      <td>15915.186041</td>\n",
       "      <td>6585.376102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201011007</td>\n",
       "      <td>4312.098530</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>217031476</td>\n",
       "      <td>4111.484475</td>\n",
       "      <td>4211.361160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>217041477</td>\n",
       "      <td>7186.714909</td>\n",
       "      <td>3434.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>217041478</td>\n",
       "      <td>10405.281786</td>\n",
       "      <td>5420.538505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>217041479</td>\n",
       "      <td>23254.186429</td>\n",
       "      <td>10423.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>217041480</td>\n",
       "      <td>13433.504195</td>\n",
       "      <td>6712.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SA2_CODE       Tot_P_P  Total_dwelings\n",
       "0    201011001  20756.256163     8252.000000\n",
       "1    201011002  11698.293593     6134.548371\n",
       "2    201011005   7372.079773     2943.325691\n",
       "3    201011006  15915.186041     6585.376102\n",
       "4    201011007   4312.098530     1600.000000\n",
       "..         ...           ...             ...\n",
       "517  217031476   4111.484475     4211.361160\n",
       "518  217041477   7186.714909     3434.000000\n",
       "519  217041478  10405.281786     5420.538505\n",
       "520  217041479  23254.186429    10423.000000\n",
       "521  217041480  13433.504195     6712.000000\n",
       "\n",
       "[522 rows x 3 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for year in years:\n",
    "    pop_year = projections_refined[['SA2  code',year]]\n",
    "    dwellings_year = dwellings_refined[['SA2  code',year]]\n",
    "\n",
    "    combined_df = pd.merge(pop_year, dwellings_year, on='SA2  code', suffixes=('_pop', '_dwellings'))\n",
    "\n",
    "    combined_df = combined_df.rename(columns={f\"{year}_pop\" : \"Tot_P_P\", f\"{year}_dwellings\" : 'Total_dwelings', \"SA2  code\": \"SA2_CODE\"})\n",
    "    \n",
    "    # remove Nan\n",
    "    combined_df = combined_df.dropna(subset=['SA2_CODE'])\n",
    "\n",
    "    combined_df[\"SA2_CODE\"] = combined_df[\"SA2_CODE\"].astype(int).astype(str)\n",
    "\n",
    "    data_per_year[year] = combined_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_per_year[2026]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/746563805.py:16: UserWarning: `keep_geom_type=True` in overlay resulted in 48 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  intersection = gpd.overlay(sa2_shapefile, sal_shapefile, how='intersection')\n"
     ]
    }
   ],
   "source": [
    "sa2_shapefile = gpd.read_file('../../data/landing/SA2_2021_map/SA2_2021_AUST_GDA2020.shp')\n",
    "sal_shapefile = gpd.read_file(\"../../data/landing/SAL_data/SAL_2021_AUST_GDA2020.shp\")\n",
    "\n",
    "sa2_shapefile = sa2_shapefile[sa2_shapefile['STE_NAME21'] == \"Victoria\"]\n",
    "sal_shapefile = sal_shapefile[sal_shapefile['STE_NAME21'] == \"Victoria\"]\n",
    "\n",
    "sa2_shapefile.SA2_CODE21 = sa2_shapefile.SA2_CODE21.astype(str)\n",
    "sal_shapefile.SAL_CODE21 = sal_shapefile.SAL_CODE21.astype(str)\n",
    "\n",
    "sa2_shapefile = sa2_shapefile.rename(columns={\"SA2_CODE21\": \"SA2_CODE\"})\n",
    "sal_shapefile = sal_shapefile.rename(columns={\"SAL_CODE21\" : \"SAL_CODE\"})\n",
    "\n",
    "sa2_shapefile = sa2_shapefile.to_crs('EPSG:3857')\n",
    "sal_shapefile = sal_shapefile.to_crs('EPSG:3857')\n",
    "\n",
    "intersection = gpd.overlay(sa2_shapefile, sal_shapefile, how='intersection')\n",
    "intersection['area'] = intersection.geometry.area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_per_year.values():\n",
    "    dataset[\"SA2_CODE\"] = dataset[\"SA2_CODE\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/2176660702.py:23: FutureWarning: The default value of numeric_only in aggfunc='sum' within pandas.DataFrameGroupBy.agg used in dissolve is deprecated. In pandas 2.0, numeric_only will default to False. Either specify numeric_only as additional argument in dissolve() or select only columns which should be valid for the function.\n",
      "  sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n",
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/2176660702.py:23: FutureWarning: The default value of numeric_only in aggfunc='sum' within pandas.DataFrameGroupBy.agg used in dissolve is deprecated. In pandas 2.0, numeric_only will default to False. Either specify numeric_only as additional argument in dissolve() or select only columns which should be valid for the function.\n",
      "  sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n",
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/2176660702.py:23: FutureWarning: The default value of numeric_only in aggfunc='sum' within pandas.DataFrameGroupBy.agg used in dissolve is deprecated. In pandas 2.0, numeric_only will default to False. Either specify numeric_only as additional argument in dissolve() or select only columns which should be valid for the function.\n",
      "  sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n",
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/2176660702.py:23: FutureWarning: The default value of numeric_only in aggfunc='sum' within pandas.DataFrameGroupBy.agg used in dissolve is deprecated. In pandas 2.0, numeric_only will default to False. Either specify numeric_only as additional argument in dissolve() or select only columns which should be valid for the function.\n",
      "  sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n",
      "/var/folders/vs/mmhmvz2124bdlbwz4b6zdqqh0000gn/T/ipykernel_66977/2176660702.py:23: FutureWarning: The default value of numeric_only in aggfunc='sum' within pandas.DataFrameGroupBy.agg used in dissolve is deprecated. In pandas 2.0, numeric_only will default to False. Either specify numeric_only as additional argument in dissolve() or select only columns which should be valid for the function.\n",
      "  sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n"
     ]
    }
   ],
   "source": [
    "SAL_data_per_year = {}\n",
    "\n",
    "for year, dataset in data_per_year.items():\n",
    "    # Merge SA2 data with intersection data on 'SA2_code'\n",
    "    intersection_merged = intersection.merge(dataset, on='SA2_CODE')\n",
    "    \n",
    "\n",
    "    # Calculate total area of each SA2 region\n",
    "    total_sa2_area = intersection.groupby('SA2_CODE')['area'].sum().reset_index()\n",
    "    total_sa2_area = total_sa2_area.rename(columns={'area': 'total_sa2_area'})\n",
    "\n",
    "    # Merge the total SA2 area back to the intersection dataframe\n",
    "    intersection_merged = intersection_merged.merge(total_sa2_area, on='SA2_CODE')\n",
    "\n",
    "    # Calculate area weight for each intersection\n",
    "    intersection_merged['area_weight'] = intersection_merged['area'] / intersection_merged['total_sa2_area']\n",
    "\n",
    "    # Assuming the attribute to be weighted is 'attribute_of_interest'\n",
    "    intersection_merged['weighted_pop'] = intersection_merged['Tot_P_P'] * intersection_merged['area_weight']\n",
    "    intersection_merged['weighted_dwellings'] = intersection_merged['Total_dwelings'] * intersection_merged['area_weight']\n",
    "\n",
    "    # Sum the weighted attribute values by SAL_code to get the final result\n",
    "    sal_weighted = intersection_merged.dissolve(by='SAL_CODE', aggfunc='sum')[['Tot_P_P', 'Total_dwelings']]\n",
    "\n",
    "    sal_weighted.reset_index(inplace=True)\n",
    "\n",
    "    SAL_data_per_year[year] = sal_weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAL_CODE</th>\n",
       "      <th>Tot_P_P</th>\n",
       "      <th>Total_dwelings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>17754</td>\n",
       "      <td>6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>25741</td>\n",
       "      <td>10700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>33389</td>\n",
       "      <td>12449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>6019</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>9897</td>\n",
       "      <td>3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>22940</td>\n",
       "      <td>6165</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>22941</td>\n",
       "      <td>19677</td>\n",
       "      <td>5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>22942</td>\n",
       "      <td>10589</td>\n",
       "      <td>3935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>22943</td>\n",
       "      <td>22454</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>22944</td>\n",
       "      <td>17578</td>\n",
       "      <td>6794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2913 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAL_CODE  Tot_P_P  Total_dwelings\n",
       "0       20001    17754            6528\n",
       "1       20002    25741           10700\n",
       "2       20003    33389           12449\n",
       "3       20004     6019            2172\n",
       "4       20005     9897            3968\n",
       "...       ...      ...             ...\n",
       "2908    22940     6165            2215\n",
       "2909    22941    19677            5720\n",
       "2910    22942    10589            3935\n",
       "2911    22943    22454            7973\n",
       "2912    22944    17578            6794\n",
       "\n",
       "[2913 rows x 3 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAL_data_per_year[2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year SAL_CODE  Total_dwelings       Tot_P_P\n",
      "0      2016    20001     7043.000000  18828.000000\n",
      "1      2016    20002    28409.000000  64918.000000\n",
      "2      2016    20003    25960.000000  64490.000000\n",
      "3      2016    20004     2409.000000   6585.000000\n",
      "4      2016    20005     4587.000000  11010.000000\n",
      "...     ...      ...             ...           ...\n",
      "47099  2031    22940     3644.689170   6825.182854\n",
      "47100  2031    22941    28302.000000  83687.310308\n",
      "47101  2031    22942     8021.519874  11160.263714\n",
      "47102  2031    22943    11362.695151  26379.073986\n",
      "47103  2031    22944     9730.036956  17724.018674\n",
      "\n",
      "[47104 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Years to interpolate (from 2016 to 2031)\n",
    "interp_years = list(range(2016, 2032))\n",
    "\n",
    "# Step 1: Consolidate Data\n",
    "# Combine all DataFrames into one\n",
    "combined_df = pd.DataFrame()\n",
    "for year, df in SAL_data_per_year.items():\n",
    "    df = df.copy()\n",
    "    df['Year'] = year\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Step 2: Prepare for Interpolation\n",
    "# Get the list of unique SAL_CODEs\n",
    "sal_codes = combined_df['SAL_CODE'].unique()\n",
    "\n",
    "# Variables to interpolate\n",
    "variables = ['Total_dwelings', 'Tot_P_P']\n",
    "\n",
    "# Initialize a list to store interpolated data\n",
    "interpolated_data = []\n",
    "\n",
    "# Step 3: Perform Interpolation\n",
    "for sal_code in sal_codes:\n",
    "    # Filter data for the current SAL_CODE\n",
    "    sal_data = combined_df[combined_df['SAL_CODE'] == sal_code]\n",
    "\n",
    "    for variable in variables:\n",
    "        # Extract known years and values for the current variable\n",
    "        known_years = sal_data['Year'].values\n",
    "        known_values = sal_data[variable].values\n",
    "\n",
    "        # Check if there are enough data points\n",
    "        if len(known_years) < 2:\n",
    "            continue  # Skip if not enough data\n",
    "\n",
    "        # Perform linear interpolation\n",
    "        interp_func = np.interp\n",
    "\n",
    "        # Interpolated values\n",
    "        interp_values = interp_func(interp_years, known_years, known_values)\n",
    "\n",
    "        # Create a DataFrame for the interpolated data\n",
    "        interp_df = pd.DataFrame({\n",
    "            'Year': interp_years,\n",
    "            'SAL_CODE': sal_code,\n",
    "            variable: interp_values\n",
    "        })\n",
    "\n",
    "        # If the variable is 'Total_dwellings', initiate the DataFrame\n",
    "        if variable == variables[0]:\n",
    "            sal_interp_df = interp_df\n",
    "        else:\n",
    "            # Merge with the existing DataFrame\n",
    "            sal_interp_df = pd.merge(sal_interp_df, interp_df, on=['Year', 'SAL_CODE'])\n",
    "\n",
    "    # Append the interpolated data for the current SAL_CODE\n",
    "    interpolated_data.append(sal_interp_df)\n",
    "\n",
    "# Step 4: Combine All Interpolated Data\n",
    "# Concatenate all interpolated DataFrames\n",
    "final_interpolated_df = pd.concat(interpolated_data, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by Year and SAL_CODE for better readability\n",
    "final_interpolated_df.sort_values(by=['Year', 'SAL_CODE'], inplace=True)\n",
    "\n",
    "# Reset index\n",
    "final_interpolated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the interpolated data\n",
    "print(final_interpolated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Year'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[244], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2016\u001b[39m,\u001b[38;5;241m2031\u001b[39m):\n\u001b[1;32m      8\u001b[0m     by_year \u001b[38;5;241m=\u001b[39m final_interpolated_df[final_interpolated_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m year]\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mby_year\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# save file\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     by_year\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/curated/pop_projections/pop_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ADS/lib/python3.11/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Year'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# group by year\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../../data/curated/pop_projections\",exist_ok=True)\n",
    "\n",
    "for year in range(2016,2031):\n",
    "    by_year = final_interpolated_df[final_interpolated_df[\"Year\"] == year]\n",
    "\n",
    "    by_year.drop(labels=['Year'], axis=1)\n",
    "\n",
    "    # save file\n",
    "    by_year.to_csv(f\"../../data/curated/pop_projections/pop_{year}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
